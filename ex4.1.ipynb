{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387cdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import (\n",
    "    Dataset,\n",
    ")  # 型アノテーション用にインポート（必須ではないが明示的に）\n",
    "from torch_geometric.nn import GINConv  # GIN（Graph Isomorphism Network）層を使用\n",
    "from torch_geometric.utils import scatter  # グラフのノードからグラフ単位への集約関数\n",
    "from torch_geometric.loader import (\n",
    "    DataLoader,\n",
    ")  # PyGのDataLoader（複数のグラフをバッチ処理）\n",
    "from torch_geometric.datasets import (\n",
    "    TUDataset,\n",
    ")  # TUDataset（MUTAGなどのグラフ分類データセット）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a05595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/NCI1.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# データセットの準備と分割\n",
    "# ===============================\n",
    "\n",
    "# TUDataset から \"NCI1\" というグラフ分類用データセットを読み込む（各データが1つのグラフ）\n",
    "dataset: TUDataset = TUDataset(root=\"/tmp/nci1\", name=\"NCI1\")\n",
    "\n",
    "# データセット全体をランダムにシャッフル\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "# 全体の90%を学習用、残り10%をテスト用に使用\n",
    "n_train: int = len(dataset) // 10 * 9  # 学習用データ数（90%）\n",
    "n_test: int = len(dataset) - n_train  # テスト用データ数（残り10%）\n",
    "\n",
    "# データセットを分割\n",
    "train_dataset: TUDataset = dataset[:n_train]  # 学習用データセット\n",
    "test_dataset: TUDataset = dataset[n_train:]  # テスト用データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a0d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# MLP：多層パーセプトロン（GINConv 内部で使用）\n",
    "# ===============================\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_d: int, mid_d: int, out_d: int):\n",
    "        \"\"\"\n",
    "        GINConv の中で使われる2層MLP（BatchNorm + ReLU付き）\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_d, mid_d),  # 入力層 → 中間層\n",
    "            nn.BatchNorm1d(mid_d),  # バッチ正規化\n",
    "            nn.ReLU(),  # 活性化関数\n",
    "            nn.Linear(mid_d, out_d),  # 中間層 → 出力層\n",
    "            nn.BatchNorm1d(out_d),  # バッチ正規化\n",
    "            nn.ReLU(),  # 活性化関数\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# GIN：Graph Isomorphism Network\n",
    "# ===============================\n",
    "class GIN(nn.Module):\n",
    "    def __init__(self, in_d: int, mid_d: int, out_d: int):\n",
    "        \"\"\"\n",
    "        GINモデルの定義\n",
    "        - 3層のGINConvを通じてノード埋め込みを生成し、\n",
    "        - グラフレベルの分類を行う\n",
    "        \"\"\"\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        # 入力特徴量を最初にMLPで変換\n",
    "        self.first_layer = MLP(in_d, mid_d, mid_d)\n",
    "\n",
    "        # GINConv 層（MLPベース）\n",
    "        self.conv1 = GINConv(MLP(mid_d, mid_d, mid_d))\n",
    "        self.conv2 = GINConv(MLP(mid_d, mid_d, mid_d))\n",
    "        self.conv3 = GINConv(MLP(mid_d, mid_d, mid_d))\n",
    "\n",
    "        # グラフ埋め込みを使って分類する予測器（2層MLP）\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(mid_d, mid_d),\n",
    "            nn.BatchNorm1d(mid_d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mid_d, out_d),\n",
    "        )\n",
    "\n",
    "    def forward(self, data: Data) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        順伝播処理\n",
    "        data.x: ノード特徴行列 (shape: [num_nodes, in_d])\n",
    "        data.edge_index: 隣接関係を示すインデックス (shape: [2, num_edges])\n",
    "        data.batch: 各ノードが属するグラフのインデックス (shape: [num_nodes])\n",
    "        \"\"\"\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # 入力特徴量をMLPで変換\n",
    "        x = self.first_layer(x)\n",
    "\n",
    "        # GINConv を3層通す（ノード埋め込みの更新）\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # グラフごとに max pooling をしてグラフ特徴量を得る\n",
    "        graph_embeddings = scatter(x, batch, dim=0, reduce=\"max\")\n",
    "\n",
    "        # グラフ埋め込みをMLPで分類\n",
    "        res = self.predictor(graph_embeddings)\n",
    "\n",
    "        # 出力を log_softmax で正規化して返す（分類用）\n",
    "        return F.log_softmax(res, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c35746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIN モデルのインスタンスを作成する\n",
    "# - 入力次元数: dataset.num_node_features（各ノードの特徴量の次元数）\n",
    "# - 中間層の次元数: 32（埋め込みの次元数。任意に設定）\n",
    "# - 出力次元数: dataset.num_classes（分類対象のクラス数）\n",
    "\n",
    "model = GIN(\n",
    "    in_d=dataset.num_node_features,  # 入力特徴量の次元数（例：ノードの特徴ベクトルの長さ）\n",
    "    mid_d=32,  # 中間表現の次元数（ハイパーパラメータとして調整可能）\n",
    "    out_d=dataset.num_classes,  # クラス数（出力層のノード数）\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc740ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 最適化手法の定義（SGD: 確率的勾配降下法）\n",
    "# ===============================\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),  # モデル内の全パラメータ（勾配更新対象）\n",
    "    lr=1e-2,  # 学習率（learning rate）0.01\n",
    "    weight_decay=1e-4,  # 重み減衰（L2正則化）係数：過学習防止のため\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e23de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch: int) -> None:\n",
    "    \"\"\"\n",
    "    GINモデルの学習を行う関数\n",
    "\n",
    "    Parameters:\n",
    "        epoch (int): 学習エポック数（何回データセット全体を学習するか）\n",
    "    \"\"\"\n",
    "    model.train()  # モデルを学習モードに設定（BatchNormやDropoutが有効になる）\n",
    "\n",
    "    # 学習用データセットからバッチ単位でデータをロードするためのDataLoaderを作成\n",
    "    loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # 指定されたエポック数だけ学習ループを回す\n",
    "    for i in range(epoch):\n",
    "        for data in loader:\n",
    "            optimizer.zero_grad()  # 勾配を初期化（前エポックの勾配をクリア）\n",
    "            out = model(\n",
    "                data\n",
    "            )  # モデルにデータを入力して出力を得る（ロジット or ログソフトマックス）\n",
    "            loss = F.nll_loss(out, data.y)  # 負の対数尤度損失を計算（分類タスク）\n",
    "            loss.backward()  # 損失関数に基づいて勾配を計算（誤差逆伝播）\n",
    "            optimizer.step()  # パラメータを1ステップ更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013aaf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 39s, sys: 2min, total: 7min 39s\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%time train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28166275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8077858880778589"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを評価モードに設定（BatchNormやDropoutが推論モードになる）\n",
    "model.eval()\n",
    "\n",
    "# 正解数を累積する変数\n",
    "acc: int = 0\n",
    "\n",
    "# テストデータセットを32件ずつバッチ処理\n",
    "for data in DataLoader(test_dataset, batch_size=32):\n",
    "    # モデルの出力から予測クラスを取得（最大スコアのインデックス）\n",
    "    pred = model(data).max(1)[1]  # .max(1)[1] は argmax と同義（最大値のインデックス）\n",
    "\n",
    "    # 予測と正解ラベルが一致した数を加算\n",
    "    acc += pred.eq(data.y).sum().item()\n",
    "\n",
    "# テスト全体に対する正解率（Accuracy）を計算\n",
    "acc / len(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
