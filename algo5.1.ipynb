{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b80ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# PyTorch Geometric による GCN 学習準備\n",
    "# ===============================\n",
    "\n",
    "# 時間計測用モジュール（学習時間の測定などに使用）\n",
    "import time\n",
    "\n",
    "# PyTorch本体のインポート（テンソル操作、モデル構築などに使用）\n",
    "import torch\n",
    "\n",
    "# PyTorch の関数型API（活性化関数、損失関数などを利用）\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GCNConv モジュールのインポート（Graph Convolutional Network の1層を構成）\n",
    "# - メッセージパッシングベースのグラフ畳み込み演算\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Redditデータセットの読み込み用モジュール\n",
    "# - ノード分類のベンチマークタスクとして有名\n",
    "from torch_geometric.datasets import Reddit\n",
    "\n",
    "# 近傍サンプリングを使ったデータローダ\n",
    "# - 大規模グラフを扱う際に、各ミニバッチで近傍ノードをサンプリングして効率化\n",
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef4b336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983.9752065760952\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Redditデータセットの読み込みと平均次数の計算\n",
    "# ===============================\n",
    "\n",
    "# Reddit データセットをローカルの /tmp/Reddit ディレクトリにダウンロード＆キャッシュ\n",
    "# - 自動的に前処理済みの PyG 形式データに変換される\n",
    "# - dataset[0] はこのデータセット内の唯一のグラフデータ（大規模な単一グラフ）\n",
    "dataset = Reddit(root=\"/tmp/Reddit\")\n",
    "\n",
    "# dataset[0] で得られるのは 1 つの Data オブジェクト\n",
    "# - data.x: ノード特徴行列（[num_nodes, num_node_features]）\n",
    "# - data.edge_index: エッジ情報（[2, num_edges] のインデックス形式）\n",
    "# - data.y: ノードのラベル（整数）\n",
    "# - その他、train_mask, val_mask, test_mask 等のマスクも含まれる\n",
    "data = dataset[0]\n",
    "\n",
    "# グラフの平均次数を表示\n",
    "# - data.num_edges：エッジ数（片方向で数える）\n",
    "# - data.num_nodes：ノード数\n",
    "# - 無向グラフでは、全エッジ数 = ノードの次数の合計 / 2\n",
    "#   → よって、平均次数は 2 * (エッジ数 / ノード数)\n",
    "print(2 * data.num_edges / data.num_nodes)  # 平均次数の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6c3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# GCN（Graph Convolutional Network）モデルの定義\n",
    "# - 2層のGCNConvを用いたシンプルなノード分類モデル\n",
    "# ===============================\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_d, mid_d, out_d):\n",
    "        super().__init__()\n",
    "\n",
    "        # 第1層：入力次元 → 中間次元 への GCNConv（グラフ畳み込み層）\n",
    "        # - 各ノードの特徴ベクトルを近傍ノードと融合しながら変換\n",
    "        self.conv1 = GCNConv(in_d, mid_d)\n",
    "\n",
    "        # 第2層：中間次元 → 出力次元（クラス数）への GCNConv\n",
    "        self.conv2 = GCNConv(mid_d, out_d)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # ノード特徴行列とエッジ情報を抽出\n",
    "        # - data.x: ノード特徴（[num_nodes, in_d]）\n",
    "        # - data.edge_index: 隣接ノードのペア情報（[2, num_edges]）\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # 第1層のGCN演算：各ノードが近傍ノードの情報を集約しつつ次元変換\n",
    "        x = self.conv1(x, edge_index)\n",
    "\n",
    "        # 活性化関数ReLUを適用（非線形変換）\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # 第2層のGCN演算（出力次元への変換）\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # 出力を softmax（対数形式）に変換して返す\n",
    "        # - 各ノードに対するクラス分類の対数確率ベクトル（[num_nodes, out_d]）\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3438ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# テストデータに対するモデルの分類精度（accuracy）を計算する関数\n",
    "# ===============================\n",
    "def calc_acc(model):\n",
    "    # モデルを推論モードに切り替え（ドロップアウトやBatchNormを無効化）\n",
    "    model.eval()\n",
    "\n",
    "    # モデルにデータを入力し、出力のクラスごとのスコアを取得\n",
    "    # - 出力形状: [num_nodes, num_classes]\n",
    "    # - argmax(dim=1)：各ノードについて最大スコアのクラスを予測ラベルとして選ぶ\n",
    "    pred = model(data).argmax(dim=1)\n",
    "\n",
    "    # テストノード（data.test_mask が True）に限定して、正解と一致した数をカウント\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "\n",
    "    # テストデータの総数で割って、分類精度（accuracy）を計算\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "    # 精度（0〜1の浮動小数）を返す\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8931a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# モデルと最適化手法（Optimizer）の初期化\n",
    "# ===============================\n",
    "\n",
    "# GCN モデルのインスタンスを生成\n",
    "# - 入力次元：dataset.num_node_features → ノード特徴の次元数（Redditでは 602）\n",
    "# - 中間層の次元数：32（隠れ層のユニット数）\n",
    "# - 出力次元：dataset.num_classes → 分類クラス数（Redditでは 41）\n",
    "model = GCN(dataset.num_node_features, 32, dataset.num_classes)\n",
    "\n",
    "# 最適化手法として Adam Optimizer を使用\n",
    "# - 学習率 lr=0.1：勾配更新のステップサイズ（やや大きめ）\n",
    "# - weight_decay=1e-4：L2正則化項。過学習を抑制する効果がある\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a2d1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# GCN モデルの学習関数\n",
    "# 引数 epoch：学習エポック数\n",
    "# ===============================\n",
    "def train(epoch):\n",
    "    # モデルを訓練モードに設定（Dropout などが有効になる）\n",
    "    model.train()\n",
    "\n",
    "    # 学習開始時刻を記録（経過時間を計測するため）\n",
    "    start = time.time()\n",
    "\n",
    "    # 指定されたエポック数だけ学習を繰り返す\n",
    "    for epoch in range(epoch):\n",
    "        # 勾配の初期化（前エポックの値をクリア）\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 順伝播を実行して出力（全ノードに対してクラスごとの対数確率を出力）\n",
    "        out = model(data)\n",
    "\n",
    "        # 損失関数の計算（教師あり損失）\n",
    "        # - 対象：train_mask が True のノードだけ\n",
    "        # - 損失関数：負の対数尤度損失（log_softmax に対応）\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "        # 誤差逆伝播によって勾配を計算\n",
    "        loss.backward()\n",
    "\n",
    "        # 勾配に基づいてパラメータを更新\n",
    "        optimizer.step()\n",
    "\n",
    "        # テストマスク上でモデルの分類精度（accuracy）を計算\n",
    "        acc = calc_acc(model)\n",
    "\n",
    "        # 経過時間を記録（1エポック目からの合計）\n",
    "        total_time = time.time() - start\n",
    "\n",
    "        # エポック番号・学習時間・精度を表示\n",
    "        print(\n",
    "            str(epoch + 1) + \" エポック目\",\n",
    "            format(total_time, \".2f\") + \" 秒\",\n",
    "            \"精度 \" + format(acc, \".4f\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a48d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f02c253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# GCNモデルの定義と最適化手法（SGD）の設定\n",
    "# ===============================\n",
    "\n",
    "# GCNモデルのインスタンス化\n",
    "# - 入力次元：dataset.num_node_features → Reddit では 602次元\n",
    "# - 中間層次元：32次元（任意に設定）\n",
    "# - 出力次元：dataset.num_classes → Reddit では 41クラス（subredditカテゴリ）\n",
    "model = GCN(dataset.num_node_features, 32, dataset.num_classes)\n",
    "\n",
    "# 最適化手法に SGD（確率的勾配降下法）を使用\n",
    "# - 学習率 lr=0.1：1ステップの更新量（比較的大きめ）\n",
    "# - weight_decay=1e-4：L2正則化係数（過学習防止）\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "386546c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# GCNの近傍サンプリング付きミニバッチ学習\n",
    "# - NeighborLoader による大規模グラフ学習の効率化\n",
    "# ===============================\n",
    "def train_neighborhood_sampling(epoch, batch_size=128):\n",
    "    # モデルを訓練モードに設定（Dropoutなど有効化）\n",
    "    model.train()\n",
    "\n",
    "    # NeighborLoader を用いてサンプルバッチを構築\n",
    "    loader = NeighborLoader(\n",
    "        data,  # グラフ全体のデータオブジェクト\n",
    "        num_neighbors=[5]\n",
    "        * 2,  # 各 GCN層で 5-hop までの隣接ノードをサンプリング（2層分）\n",
    "        batch_size=batch_size,  # 1回のバッチに含める中心ノード数\n",
    "        input_nodes=data.train_mask,  # バッチの中心ノード候補（訓練ノードのみ）\n",
    "    )\n",
    "\n",
    "    # 時間計測の開始\n",
    "    start = time.time()\n",
    "\n",
    "    # エポック数（epoch）だけ学習ループを回す\n",
    "    for epoch in range(epoch):\n",
    "        for sampled_data in loader:\n",
    "            # 勾配初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # サンプリングされたサブグラフをモデルに入力して予測出力を得る\n",
    "            out = model(sampled_data)\n",
    "\n",
    "            # ロス計算（バッチサイズ分の中心ノードに対して）\n",
    "            # - NeighborLoader によるサンプルは「中心ノード + その近傍」で構成される\n",
    "            # - `out[:batch_size]` により中心ノード部分のみを損失計算の対象とする\n",
    "            loss = F.nll_loss(out[:batch_size], sampled_data.y[:batch_size])\n",
    "\n",
    "            # 勾配計算と最適化ステップ\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 1エポックごとに全体精度を評価（グローバルテストマスクを使用）\n",
    "        acc = calc_acc(model)\n",
    "\n",
    "        # 経過時間を計算\n",
    "        total_time = time.time() - start\n",
    "\n",
    "        # エポックごとの結果を表示\n",
    "        print(\n",
    "            str(epoch + 1) + \" エポック目\",\n",
    "            format(total_time, \".2f\") + \" 秒\",\n",
    "            \"精度 \" + format(acc, \".4f\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7becb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeighborLoader による近傍サンプリングを使うことで、\n",
    "# - 各エポックで処理するノード数が少なくなるため、1エポックあたりの計算時間が短縮される\n",
    "# - また、ミニバッチ学習のため、1エポック内に複数回パラメータが更新される（バッチ数ぶん）\n",
    "# → 結果として、全体の学習が高速に進み、必要なエポック数も少なくて済む傾向がある\n",
    "train_neighborhood_sampling(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
