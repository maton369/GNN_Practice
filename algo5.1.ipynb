{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b80ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# PyTorch Geometric による GCN 学習準備\n",
    "# ===============================\n",
    "\n",
    "# 時間計測用モジュール（学習時間の測定などに使用）\n",
    "import time\n",
    "\n",
    "# PyTorch本体のインポート（テンソル操作、モデル構築などに使用）\n",
    "import torch\n",
    "\n",
    "# PyTorch の関数型API（活性化関数、損失関数などを利用）\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GCNConv モジュールのインポート（Graph Convolutional Network の1層を構成）\n",
    "# - メッセージパッシングベースのグラフ畳み込み演算\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Redditデータセットの読み込み用モジュール\n",
    "# - ノード分類のベンチマークタスクとして有名\n",
    "from torch_geometric.datasets import Reddit\n",
    "\n",
    "# 近傍サンプリングを使ったデータローダ\n",
    "# - 大規模グラフを扱う際に、各ミニバッチで近傍ノードをサンプリングして効率化\n",
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef4b336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.dgl.ai/dataset/reddit.zip\n",
      "Extracting /tmp/Reddit/raw/reddit.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983.9752065760952\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Redditデータセットの読み込みと平均次数の計算\n",
    "# ===============================\n",
    "\n",
    "# Reddit データセットをローカルの /tmp/Reddit ディレクトリにダウンロード＆キャッシュ\n",
    "# - 自動的に前処理済みの PyG 形式データに変換される\n",
    "# - dataset[0] はこのデータセット内の唯一のグラフデータ（大規模な単一グラフ）\n",
    "dataset = Reddit(root=\"/tmp/Reddit\")\n",
    "\n",
    "# dataset[0] で得られるのは 1 つの Data オブジェクト\n",
    "# - data.x: ノード特徴行列（[num_nodes, num_node_features]）\n",
    "# - data.edge_index: エッジ情報（[2, num_edges] のインデックス形式）\n",
    "# - data.y: ノードのラベル（整数）\n",
    "# - その他、train_mask, val_mask, test_mask 等のマスクも含まれる\n",
    "data = dataset[0]\n",
    "\n",
    "# グラフの平均次数を表示\n",
    "# - data.num_edges：エッジ数（片方向で数える）\n",
    "# - data.num_nodes：ノード数\n",
    "# - 無向グラフでは、全エッジ数 = ノードの次数の合計 / 2\n",
    "#   → よって、平均次数は 2 * (エッジ数 / ノード数)\n",
    "print(2 * data.num_edges / data.num_nodes)  # 平均次数の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6c3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# GCN（Graph Convolutional Network）モデルの定義\n",
    "# - 2層のGCNConvを用いたシンプルなノード分類モデル\n",
    "# ===============================\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_d, mid_d, out_d):\n",
    "        super().__init__()\n",
    "\n",
    "        # 第1層：入力次元 → 中間次元 への GCNConv（グラフ畳み込み層）\n",
    "        # - 各ノードの特徴ベクトルを近傍ノードと融合しながら変換\n",
    "        self.conv1 = GCNConv(in_d, mid_d)\n",
    "\n",
    "        # 第2層：中間次元 → 出力次元（クラス数）への GCNConv\n",
    "        self.conv2 = GCNConv(mid_d, out_d)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # ノード特徴行列とエッジ情報を抽出\n",
    "        # - data.x: ノード特徴（[num_nodes, in_d]）\n",
    "        # - data.edge_index: 隣接ノードのペア情報（[2, num_edges]）\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # 第1層のGCN演算：各ノードが近傍ノードの情報を集約しつつ次元変換\n",
    "        x = self.conv1(x, edge_index)\n",
    "\n",
    "        # 活性化関数ReLUを適用（非線形変換）\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # 第2層のGCN演算（出力次元への変換）\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # 出力を softmax（対数形式）に変換して返す\n",
    "        # - 各ノードに対するクラス分類の対数確率ベクトル（[num_nodes, out_d]）\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3438ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# テストデータに対するモデルの分類精度（accuracy）を計算する関数\n",
    "# ===============================\n",
    "def calc_acc(model):\n",
    "    # モデルを推論モードに切り替え（ドロップアウトやBatchNormを無効化）\n",
    "    model.eval()\n",
    "\n",
    "    # モデルにデータを入力し、出力のクラスごとのスコアを取得\n",
    "    # - 出力形状: [num_nodes, num_classes]\n",
    "    # - argmax(dim=1)：各ノードについて最大スコアのクラスを予測ラベルとして選ぶ\n",
    "    pred = model(data).argmax(dim=1)\n",
    "\n",
    "    # テストノード（data.test_mask が True）に限定して、正解と一致した数をカウント\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "\n",
    "    # テストデータの総数で割って、分類精度（accuracy）を計算\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "    # 精度（0〜1の浮動小数）を返す\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8931a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# モデルと最適化手法（Optimizer）の初期化\n",
    "# ===============================\n",
    "\n",
    "# GCN モデルのインスタンスを生成\n",
    "# - 入力次元：dataset.num_node_features → ノード特徴の次元数（Redditでは 602）\n",
    "# - 中間層の次元数：32（隠れ層のユニット数）\n",
    "# - 出力次元：dataset.num_classes → 分類クラス数（Redditでは 41）\n",
    "model = GCN(dataset.num_node_features, 32, dataset.num_classes)\n",
    "\n",
    "# 最適化手法として Adam Optimizer を使用\n",
    "# - 学習率 lr=0.1：勾配更新のステップサイズ（やや大きめ）\n",
    "# - weight_decay=1e-4：L2正則化項。過学習を抑制する効果がある\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a2d1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# GCN モデルの学習関数\n",
    "# 引数 epoch：学習エポック数\n",
    "# ===============================\n",
    "def train(epoch):\n",
    "    # モデルを訓練モードに設定（Dropout などが有効になる）\n",
    "    model.train()\n",
    "\n",
    "    # 学習開始時刻を記録（経過時間を計測するため）\n",
    "    start = time.time()\n",
    "\n",
    "    # 指定されたエポック数だけ学習を繰り返す\n",
    "    for epoch in range(epoch):\n",
    "        # 勾配の初期化（前エポックの値をクリア）\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 順伝播を実行して出力（全ノードに対してクラスごとの対数確率を出力）\n",
    "        out = model(data)\n",
    "\n",
    "        # 損失関数の計算（教師あり損失）\n",
    "        # - 対象：train_mask が True のノードだけ\n",
    "        # - 損失関数：負の対数尤度損失（log_softmax に対応）\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "        # 誤差逆伝播によって勾配を計算\n",
    "        loss.backward()\n",
    "\n",
    "        # 勾配に基づいてパラメータを更新\n",
    "        optimizer.step()\n",
    "\n",
    "        # テストマスク上でモデルの分類精度（accuracy）を計算\n",
    "        acc = calc_acc(model)\n",
    "\n",
    "        # 経過時間を記録（1エポック目からの合計）\n",
    "        total_time = time.time() - start\n",
    "\n",
    "        # エポック番号・学習時間・精度を表示\n",
    "        print(\n",
    "            str(epoch + 1) + \" エポック目\",\n",
    "            format(total_time, \".2f\") + \" 秒\",\n",
    "            \"精度 \" + format(acc, \".4f\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a48d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
